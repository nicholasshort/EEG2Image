{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_path = \"C:\\\\Users\\\\Nick\\\\Repos\\\\EEG2Image\\\\eeg2_data\"\n",
    "subjects = [\"sub-01\"]\n",
    "# subjects = [\n",
    "#         # \"sub-01\",\n",
    "#         # \"sub-02\",\n",
    "#         # \"sub-03\",\n",
    "#         # \"sub-04\",\n",
    "#         # \"sub-05\",\n",
    "#         # \"sub-06\",\n",
    "#         # \"sub-07\",\n",
    "#         # \"sub-08\",\n",
    "#         # \"sub-09\", \n",
    "#         # \"sub-10\",\n",
    "#     ]  # 20GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_EEG_dataset(path, subjects):\n",
    "    subject_eeg_train_data = {}\n",
    "    subject_eeg_test_data = {}\n",
    "    # Obtains data per subject and adds it into the dictionary\n",
    "    for subject in subjects:\n",
    "        print(\"Loading\", subject)\n",
    "        eeg_parent_dir = os.path.join(path, 'preprocessed_data', subject)\n",
    "        eeg_data_train = np.load(os.path.join(eeg_parent_dir, 'preprocessed_eeg_training.npy'), allow_pickle=True).item()\n",
    "        print(eeg_data_train.keys())\n",
    "        eeg_data_test = np.load(os.path.join(eeg_parent_dir, 'preprocessed_eeg_test.npy'), allow_pickle=True).item()\n",
    "        subject_eeg_train_data[subject] = eeg_data_train\n",
    "        subject_eeg_test_data[subject] = eeg_data_test\n",
    "\n",
    "        print('Training EEG data shape per subject:')\n",
    "        print(eeg_data_train['preprocessed_eeg_data'].shape, '- (Training image conditions × Training EEG repetitions × EEG channels × '\n",
    "            'EEG time points)')\n",
    "        print('Test EEG data shape per subject:')\n",
    "        print(eeg_data_test['preprocessed_eeg_data'].shape, '- (Test image conditions × Test EEG repetitions × EEG channels × '\n",
    "            'EEG time points)\\n')\n",
    "    \n",
    "        \n",
    "    return subject_eeg_train_data, subject_eeg_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_dataset(path):\n",
    "    img_parent_dir  = os.path.join(dataset_path, 'image_set')\n",
    "    img_metadata = np.load(os.path.join(img_parent_dir, 'image_metadata.npy'),\n",
    "        allow_pickle=True).item()\n",
    "    \n",
    "    train_images = []\n",
    "    for train_img_idx in range(len(img_metadata['train_img_files'])):\n",
    "        dataset_img_dir = os.path.join(img_parent_dir, 'training_images', img_metadata['train_img_concepts'][train_img_idx], img_metadata['train_img_files'][train_img_idx])\n",
    "        dataset_img = Image.open(dataset_img_dir).convert('RGB')\n",
    "        train_images.append(dataset_img)\n",
    "    \n",
    "    test_images = []\n",
    "    for test_img_idx in range(len(img_metadata['test_img_files'])):\n",
    "        dataset_img_dir = os.path.join(img_parent_dir, 'test_images', img_metadata['test_img_concepts'][test_img_idx], img_metadata['test_img_files'][test_img_idx])\n",
    "        dataset_img = Image.open(dataset_img_dir).convert('RGB')\n",
    "        test_images.append(dataset_img)\n",
    "\n",
    "    # 10 images per concept.\n",
    "    n_train_img = len(img_metadata['train_img_concepts'])\n",
    "    n_train_concepts = len(np.unique(img_metadata['train_img_concepts']))\n",
    "    n_train_img_per_concept = int(n_train_img / n_train_concepts)\n",
    "    print('Training images: ' + str(n_train_img))\n",
    "    print('Training image concepts: ' + str(n_train_concepts))\n",
    "    print('Training images per concept: '+ str(n_train_img_per_concept))\n",
    "\n",
    "    # 1 image per concept.\n",
    "    n_test_img = len(img_metadata['test_img_concepts'])\n",
    "    n_test_concepts = len(np.unique(img_metadata['test_img_concepts']))\n",
    "    n_test_img_per_concept = int(n_test_img / n_test_concepts)\n",
    "    print('Test images: ' + str(n_test_img))\n",
    "    print('Test image concepts: ' + str(n_test_concepts))\n",
    "    print('Test images per concept: ' + str(n_test_img_per_concept))\n",
    "    return train_images, test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the eeg dataset:...\n",
      "Loading sub-01\n",
      "dict_keys(['preprocessed_eeg_data', 'ch_names', 'times'])\n",
      "Training EEG data shape per subject:\n",
      "(16540, 4, 17, 100) - (Training image conditions × Training EEG repetitions × EEG channels × EEG time points)\n",
      "Test EEG data shape per subject:\n",
      "(200, 80, 17, 100) - (Test image conditions × Test EEG repetitions × EEG channels × EEG time points)\n",
      "\n",
      "(16540, 17, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Loading the eeg dataset:...')\n",
    "eeg_train_data, eeg_test_data = create_EEG_dataset(dataset_path, subjects)\n",
    "sub_01_avg_data = np.expand_dims(np.mean(eeg_train_data['sub-01']['preprocessed_eeg_data'], axis=1), axis=3)\n",
    "\n",
    "print(sub_01_avg_data.shape)\n",
    "\n",
    "# print('\\nLoading the image dataset:...')\n",
    "# img_data = create_image_dataset(dataset_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
